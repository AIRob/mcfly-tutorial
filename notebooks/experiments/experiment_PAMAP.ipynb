{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment PAMAP with mcfly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# mcfly\n",
    "from mcfly import modelgen, find_architecture, storage\n",
    "from keras.models import load_model\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils import tutorial_pamap2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the preprocessed data as stored in Numpy-files. Please note that the data has already been split up in a training (training), validation (val), and test subsets. It is common practice to call the input data X and the labels y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/media/sf_VBox_Shared/timeseries/PAMAP_Dataset/cleaned_7act/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train_binary, X_val, y_val_binary, X_test, y_test_binary, labels = tutorial_pamap2.load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (4400, 512, 9)\n",
      "y shape: (4400, 7)\n"
     ]
    }
   ],
   "source": [
    "print('x shape:', X_train.shape)\n",
    "print('y shape:', y_train_binary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split between train test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 4400\n",
      "validation set size: 3000\n",
      "test set size: 3000\n"
     ]
    }
   ],
   "source": [
    "print('train set size:', X_train.shape[0])\n",
    "print('validation set size:', X_val.shape[0])\n",
    "print('test set size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the distribution of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lying</th>\n",
       "      <td>0.134318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sitting</th>\n",
       "      <td>0.130909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standing</th>\n",
       "      <td>0.137045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_walking</th>\n",
       "      <td>0.185682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cycling</th>\n",
       "      <td>0.117955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ironing</th>\n",
       "      <td>0.161364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vaccuum_cleaning</th>\n",
       "      <td>0.132727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  frequency\n",
       "lying              0.134318\n",
       "sitting            0.130909\n",
       "standing           0.137045\n",
       "normal_walking     0.185682\n",
       "cycling            0.117955\n",
       "ironing            0.161364\n",
       "vaccuum_cleaning   0.132727"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = y_train_binary.mean(axis=0)\n",
    "frequencies_df = pd.DataFrame(frequencies, index=labels, columns=['frequency'])\n",
    "frequencies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = y_train_binary.shape[1]\n",
    "\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 0\n",
      " \n",
      "Hyperparameters:\n",
      "{'filters': array([85, 17, 44]), 'learning_rate': 0.08360289270402858, 'regularization_rate': 0.0022439468517196116, 'fc_hidden_nodes': 443}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 512, 9)            36        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 512, 85)           2380      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512, 85)           340       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512, 85)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 512, 17)           4352      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512, 17)           68        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512, 17)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 512, 44)           2288      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512, 44)           176       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512, 44)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 443)               9980347   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 443)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                6216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 9,996,259\n",
      "Trainable params: 9,995,921\n",
      "Non-trainable params: 338\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 1\n",
      " \n",
      "Hyperparameters:\n",
      "{'filters': [48, 43, 68, 77], 'lstm_dims': [78], 'learning_rate': 0.000893145093504032, 'regularization_rate': 0.00319386451934688}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 512, 9)            36        \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 512, 9, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 512, 9, 48)        192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512, 9, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512, 9, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 9, 43)        6235      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512, 9, 43)        172       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512, 9, 43)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 512, 9, 68)        8840      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512, 9, 68)        272       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512, 9, 68)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 512, 9, 77)        15785     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512, 9, 77)        308       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512, 9, 77)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 512, 693)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512, 78)           240864    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512, 78)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 512, 14)           1106      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512, 14)           0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 274,002\n",
      "Trainable params: 273,512\n",
      "Non-trainable params: 490\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 2\n",
      " \n",
      "Hyperparameters:\n",
      "{'filters': [97, 61, 39, 54, 59, 16], 'lstm_dims': [15, 79], 'learning_rate': 0.0045162313812273, 'regularization_rate': 0.0005482537387722349}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 512, 9)            36        \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 512, 9, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 512, 9, 97)        388       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512, 9, 97)        388       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512, 9, 97)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 9, 61)        17812     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512, 9, 61)        244       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512, 9, 61)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 512, 9, 39)        7176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 512, 9, 39)        156       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512, 9, 39)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 512, 9, 54)        6372      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512, 9, 54)        216       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 512, 9, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 512, 9, 59)        9617      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 512, 9, 59)        236       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512, 9, 59)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 512, 9, 16)        2848      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 512, 9, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 512, 9, 16)        0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 512, 144)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512, 15)           9600      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 512, 79)           30020     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512, 79)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 512, 14)           1120      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512, 14)           0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 86,293\n",
      "Trainable params: 85,623\n",
      "Non-trainable params: 670\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 3\n",
      " \n",
      "Hyperparameters:\n",
      "{'filters': [82, 85, 23, 23], 'lstm_dims': [52, 73, 73, 52], 'learning_rate': 0.00011922953164184091, 'regularization_rate': 0.0028975347310818715}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_18 (Batc (None, 512, 9)            36        \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 512, 9, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 512, 9, 82)        328       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512, 9, 82)        328       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 512, 9, 82)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 512, 9, 85)        20995     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 512, 9, 85)        340       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512, 9, 85)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 512, 9, 23)        5888      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 512, 9, 23)        92        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 512, 9, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 512, 9, 23)        1610      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 512, 9, 23)        92        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 512, 9, 23)        0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 512, 207)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 512, 52)           54080     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 512, 73)           36792     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 512, 73)           42924     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 512, 52)           26208     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512, 52)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 512, 14)           742       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 512, 14)           0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 190,455\n",
      "Trainable params: 190,011\n",
      "Non-trainable params: 444\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 4\n",
      " \n",
      "Hyperparameters:\n",
      "{'filters': array([38, 13, 59, 84, 66]), 'learning_rate': 0.0010358940660228366, 'regularization_rate': 0.034561566363944925, 'fc_hidden_nodes': 129}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_23 (Batc (None, 512, 9)            36        \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 512, 38)           1064      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 512, 38)           152       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512, 38)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 512, 13)           1495      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 512, 13)           52        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 512, 13)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 512, 59)           2360      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 512, 59)           236       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 512, 59)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 512, 84)           14952     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 512, 84)           336       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 512, 84)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 512, 66)           16698     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 512, 66)           264       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 512, 66)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 33792)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 129)               4359297   \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 129)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 14)                1820      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 4,398,818\n",
      "Trainable params: 4,398,252\n",
      "Non-trainable params: 566\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n"
     ]
    }
   ],
   "source": [
    "models_to_print = range(len(models))\n",
    "for i, item in enumerate(models):\n",
    "    if i in models_to_print:\n",
    "        model, params, model_types = item\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Model \" + str(i))\n",
    "        print(\" \")\n",
    "        print(\"Hyperparameters:\")\n",
    "        print(params)\n",
    "        print(\" \")\n",
    "        print(\"Model description:\")\n",
    "        model.summary()\n",
    "        print(\" \")\n",
    "        print(\"Model type:\")\n",
    "        print(model_types)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define directory where the results, e.g. json file, will be stored\n",
    "resultpath = os.path.join(data_path, '..', 'data/models')\n",
    "if not os.path.exists(resultpath):\n",
    "        os.makedirs(resultpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 CNN\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 76s - loss: 725.5110 - acc: 0.1350 - val_loss: 316.7036 - val_acc: 0.0863\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 92s - loss: 122.9181 - acc: 0.1570 - val_loss: 32.9516 - val_acc: 0.1187\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 72s - loss: 17.9430 - acc: 0.1600 - val_loss: 13.5581 - val_acc: 0.1103\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 79s - loss: 10.0085 - acc: 0.1340 - val_loss: 8.6690 - val_acc: 0.1203\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 79s - loss: 8.5397 - acc: 0.1340 - val_loss: 8.2714 - val_acc: 0.1203\n",
      "Training model 1 DeepConvLSTM\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 702s - loss: 3.3252 - acc: 0.1930 - val_loss: 3.3953 - val_acc: 0.1197\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 671s - loss: 2.9722 - acc: 0.2860 - val_loss: 3.4453 - val_acc: 0.0960\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 682s - loss: 2.8479 - acc: 0.3260 - val_loss: 3.5679 - val_acc: 0.0787\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 742s - loss: 2.7898 - acc: 0.3140 - val_loss: 3.6878 - val_acc: 0.0960\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 777s - loss: 2.7174 - acc: 0.3280 - val_loss: 3.7686 - val_acc: 0.0927\n",
      "Training model 2 DeepConvLSTM\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 992s - loss: 2.6795 - acc: 0.1940 - val_loss: 2.7670 - val_acc: 0.1293\n",
      "Epoch 2/5\n",
      " 980/1000 [============================>.] - ETA: 10s - loss: 2.5394 - acc: 0.2133"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-79fe66803821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                            \u001b[0msubset_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                                            outputfile=outputfile)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Details of the training process were stored in '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/mcfly/find_architecture.py\u001b[0m in \u001b[0;36mtrain_models_on_samples\u001b[0;34m(X_train, y_train, X_val, y_val, models, nr_epochs, subset_size, verbose, outputfile, model_path, early_stopping, batch_size, metric)\u001b[0m\n\u001b[1;32m     91\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1195\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1196\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                                                        verbose=0)\n\u001b[0m\u001b[1;32m   1198\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1337\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputfile = os.path.join(resultpath, 'modelcomparison_pamap.json')\n",
    "histories, val_accuracies, val_losses = find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models,nr_epochs=5,\n",
    "                                                                           subset_size=1000,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=outputfile)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type and parameters of the best model:\n",
      "DeepConvLSTM\n",
      "{'lstm_dims': [78], 'learning_rate': 0.000893145093504032, 'regularization_rate': 0.00319386451934688, 'filters': [48, 43, 68, 77]}\n"
     ]
    }
   ],
   "source": [
    "best_model_index = np.argmax(val_accuracies)\n",
    "best_model, best_params, best_model_types = models[best_model_index]\n",
    "print('Model type and parameters of the best model:')\n",
    "print(best_model_types)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 293s - loss: 1.5453 - acc: 0.7600 - val_loss: 2.6561 - val_acc: 0.4600\n"
     ]
    }
   ],
   "source": [
    "#We make a copy of the model, to start training from fresh\n",
    "nr_epochs = 1\n",
    "datasize = X_train.shape[0]\n",
    "history = best_model.fit(X_train[:datasize,:,:], y_train_binary[:datasize,:],\n",
    "              epochs=nr_epochs, validation_data=(X_val, y_val_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelname = 'my_bestmodel.h5'\n",
    "model_path = os.path.join(resultpath,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mcfly]",
   "language": "python",
   "name": "conda-env-mcfly-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
